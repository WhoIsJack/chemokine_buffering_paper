{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking-Based Colocalization Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes <a id=\"notes\"></a>\n",
    "[notes](#notes) [prep](#prep) [test](#test) [run](#run)\n",
    "\n",
    "Pipeline to measure colocalization of one channel (\"1st\") within the compartments delineated by another (\"2nd\"). Works by overall background subtraction followed by Otsu thresholding of the 2nd channel and then measuring the ratio of mean intensities of the 1st channel within the 2nd channel's mask vs in the entire image. To become less influenced by irrelevant regions of the image, all this is done within a bounding box surrounding the apical center of the neuromasts (the lumen).\n",
    "\n",
    "**Note:** 8-bit conversion is done before this, using the Fiji macro `8bit_macro.ijm`. A fixed conversion range is used that is kept the same across a given experiment. Minima are always 0 or 10000 (depending on airyscan settings), maxima are adjusted based on intensity range; the values are logged in `data\\metadata.xlsx`.\n",
    "\n",
    "**Note:** For this to run the location of the apical center (the lumen position) of the neuromast has to be determined manually and its coordinates (in pixels) must be written in `<fpath>\\metadata.xlsx`, which then has to be exported as a *tab-separated text file* called `<fpath>\\metadata.txt`!\n",
    "\n",
    "\n",
    "### Pipeline Outline\n",
    "\n",
    "- Preprocessing\n",
    "    - Crop to a region around the lumen\n",
    "        - This was added to improve the quality of the measurements\n",
    "        - It makes the measurement of total intensity more precise\n",
    "        - It may also help by making the thresholding more consistent\n",
    "    - Background subtraction\n",
    "        - Either global based on background region *[preferred!]*\n",
    "        - Or local based on heavy Gaussian background\n",
    "    \n",
    "    \n",
    "- Thresholding of target vesicles (red or far-red)\n",
    "    - Either automated thresholding *[preferred]*\n",
    "        - Tested a few; Otsu looks good\n",
    "    - Or full threshold series\n",
    "        \n",
    "    \n",
    "- Measurements\n",
    "    - Use bgsubbed Cxcr7/Cxcr4 channels for measurements\n",
    "    - Get means & sums within the threshold masks and in total\n",
    "    - Final measure: the ratio `threshold_mean / total_mean` *[preferred]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep <a id=\"prep\"></a>\n",
    "[notes](#notes) [prep](#prep) [test](#test) [run](#run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "from __future__ import division\n",
    "import os, warnings, pickle, time\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imsave\n",
    "\n",
    "# Internal\n",
    "import coloc.colocalization as coloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing  <a id=\"test\"></a>\n",
    "[notes](#notes) [prep](#prep) [test](#test) [run](#run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test Data Creation\n",
    "\n",
    "# Settings\n",
    "run_test_only  = False\n",
    "\n",
    "# Parameters\n",
    "shape   = (400, 400)\n",
    "#shape   = (40, 400, 400)\n",
    "offset  = 20\n",
    "size    = (30, 20)\n",
    "max_int = (70, 60)\n",
    "bg_loc  = (30, 40)\n",
    "bg_scl  = 5\n",
    "chunk_s = 3\n",
    "\n",
    "# Channel generation function\n",
    "def create_channel(shape, offset, size=20, \n",
    "                   max_int=60, sig=7, PSF_sig=3,\n",
    "                   bg_loc=5, bg_scl=5):\n",
    "\n",
    "    # Null\n",
    "    img = np.zeros(shape, dtype=np.uint8)\n",
    "\n",
    "    # Signal\n",
    "    pos = [s//2 - size//2 for s in shape]\n",
    "    pos[0] += offset//2\n",
    "    slc = tuple(slice(p, p+size) for p in pos)\n",
    "    img[slc] = max_int\n",
    "    \n",
    "    # Smoothen signal\n",
    "    img = ndi.gaussian_filter(img, sigma=sig)\n",
    "    \n",
    "    # Background\n",
    "    img += np.abs(np.random.normal(bg_loc, bg_scl, shape)).astype(np.uint8)\n",
    "    \n",
    "    # PSF\n",
    "    img = ndi.gaussian_filter(img, sigma=PSF_sig)    \n",
    "    \n",
    "    # Detector noise\n",
    "    img += np.abs(np.random.normal(0, 2, shape)).astype(np.uint8)\n",
    "    \n",
    "    # Done\n",
    "    return img\n",
    "   \n",
    "# Create single example image\n",
    "img = np.zeros((2,)+shape, dtype=np.uint8)\n",
    "img[0] = create_channel(shape, -offset//2, size=size[0], \n",
    "                        max_int=max_int[0], PSF_sig=chunk_s/3,\n",
    "                        bg_loc=bg_loc[0], bg_scl=bg_scl)\n",
    "img[1] = create_channel(shape,  offset//2, size=size[1], \n",
    "                        max_int=max_int[1], PSF_sig=chunk_s/3,\n",
    "                        bg_loc=bg_loc[1], bg_scl=bg_scl)\n",
    "\n",
    "# Prep for plotting\n",
    "if img.ndim == 3:\n",
    "    ch0_plot = img[0,...]\n",
    "    ch1_plot = img[1,...]\n",
    "elif img.ndim == 4:\n",
    "    ch0_plot = img[0, img.shape[1]//2, ...]\n",
    "    ch1_plot = img[1, img.shape[1]//2, ...]\n",
    "    \n",
    "# Display as RGB\n",
    "rgb = np.dstack([ch0_plot, ch1_plot, np.zeros_like(ch0_plot)])\n",
    "plt.imshow(rgb, interpolation='none')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Report\n",
    "print \"max int ch0:\", np.max(img[0])\n",
    "print \"max int ch1:\", np.max(img[1])\n",
    "\n",
    "# Create full test series\n",
    "if len(shape)==2:\n",
    "    test_offsets = range(0, 101, 20)\n",
    "if len(shape)==3: \n",
    "    test_offsets = [0, 20, 40, 60, 80, 100]\n",
    "test_imgs = [] \n",
    "for test_offset in test_offsets:\n",
    "    for intensity_factor in np.linspace(1.0, 2.0, 5):\n",
    "        test_img = np.zeros((2,)+shape, dtype=np.uint8)\n",
    "        test_img[0] = create_channel(shape, -test_offset//2, size=size[0], \n",
    "                                     max_int=max_int[0], PSF_sig=chunk_s/3,\n",
    "                                     bg_loc=bg_loc[0], bg_scl=bg_scl) * intensity_factor\n",
    "        test_img[1] = create_channel(shape,  test_offset//2, size=size[1], \n",
    "                                     max_int=max_int[1], PSF_sig=chunk_s/3,\n",
    "                                     bg_loc=bg_loc[1], bg_scl=bg_scl) * intensity_factor\n",
    "        test_imgs.append(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Background Subtraction\n",
    "\n",
    "bgsub = np.zeros_like(img)\n",
    "bgsub[0, :, :] = coloc.bgsub_global(img[0, :, :])\n",
    "bgsub[1, :, :] = coloc.bgsub_global(img[1, :, :])\n",
    "#bgsub[0, :, :] = coloc.bgsub_local(img[0, :, :], sigma=10)\n",
    "#bgsub[1, :, :] = coloc.bgsub_local(img[1, :, :], sigma=10)\n",
    "\n",
    "# Prep for plotting\n",
    "if bgsub.ndim == 3:\n",
    "    ch0_plot = bgsub[0,...]\n",
    "    ch1_plot = bgsub[1,...]\n",
    "elif img.ndim == 4:\n",
    "    ch0_plot = bgsub[0, img.shape[1]//2, ...]\n",
    "    ch1_plot = bgsub[1, img.shape[1]//2, ...]\n",
    "    \n",
    "# Display as RGB\n",
    "rgb = np.dstack([ch0_plot, ch1_plot, np.zeros_like(ch0_plot)])\n",
    "plt.imshow(rgb, interpolation='none')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Thresholding & Measurement\n",
    "\n",
    "#np.seterr(all='raise')\n",
    "\n",
    "# Prep plot\n",
    "fig, ax = plt.subplots(1, 6, figsize=(12,3))\n",
    "\n",
    "# Otsu thresholding\n",
    "threshs  = []\n",
    "means    = []\n",
    "sums     = []\n",
    "m_ratios = []\n",
    "s_ratios = []\n",
    "for test_img in test_imgs:\n",
    "    test_img_bgsub_ch0 = coloc.bgsub_global(test_img[0, :, :])\n",
    "    test_img_bgsub_ch1 = coloc.bgsub_global(test_img[1, :, :])\n",
    "    t, m, s, mr, sr = coloc.thresh_detect(test_img_bgsub_ch0, test_img_bgsub_ch1)\n",
    "    #t, m, s, mr, sr, _, _, _ = thresh_detect(test_img_bgsub_ch0, test_img_bgsub_ch1)\n",
    "    threshs.append(t)\n",
    "    means.append(m)\n",
    "    sums.append(s)\n",
    "    m_ratios.append(mr)\n",
    "    s_ratios.append(sr)\n",
    "\n",
    "# Plot thresholds\n",
    "ax[0].plot(threshs)\n",
    "ax[0].set_ylim([min(threshs)-5,\n",
    "                max(threshs)+5])\n",
    "ax[0].set_xlabel('test image index')\n",
    "ax[0].set_ylabel('otsu threshold')\n",
    "\n",
    "# Plot results\n",
    "ax[1].plot(means)\n",
    "ax[1].set_xlabel('test image index')\n",
    "ax[1].set_ylabel('foreground mean')\n",
    "ax[2].plot(sums)\n",
    "ax[2].set_xlabel('test image index')\n",
    "ax[2].set_ylabel('foreground sum')\n",
    "ax[3].plot(m_ratios)\n",
    "ax[3].set_xlabel('test image index')\n",
    "ax[3].set_ylabel('foreground mean / total ratio')\n",
    "ax[4].plot(s_ratios)\n",
    "ax[4].set_xlabel('test image index')\n",
    "ax[4].set_ylabel('foreground sum / total ratio')\n",
    "\n",
    "# Threshold series\n",
    "threshs = []\n",
    "means   = []\n",
    "indices = []\n",
    "for i, test_img in enumerate(test_imgs):\n",
    "    t, m, _, _, _ = coloc.thresh_series(test_img[0,:,:], test_img[1,:,:])\n",
    "    threshs.append(t)\n",
    "    means.append(m)\n",
    "    indices.append(np.ones_like(t)*i)\n",
    "\n",
    "# Plot results\n",
    "scat = ax[5].scatter(threshs, means, \n",
    "                     c=indices, cmap='viridis', \n",
    "                     edgecolors='face')\n",
    "ax[5].set_xlabel('threshold')\n",
    "ax[5].set_ylabel('foreground mean')\n",
    "plt.colorbar(scat, label='test image index')\n",
    "\n",
    "# Done\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Data <a id=\"run\"></a>\n",
    "[notes](#notes) [prep](#prep) [test](#test) [run](#run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Halt in case only test runs should be done\n",
    "\n",
    "if run_test_only:\n",
    "    raise ValueError(\"Run terminated because `run_test_only` is set to True!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Settings\n",
    "\n",
    "# Input data\n",
    "dirpath = r'data_ex'\n",
    "suffix  = r'_8bit.tif'\n",
    "trigger = r'coloc'\n",
    "\n",
    "# Processing parameters\n",
    "region_size = (20, 150, 200)   # Has to be len (z, y, x). For 2D imgs, z is ignored.\n",
    "if 'rev' in trigger: \n",
    "    region_size = (20, 180, 240)  # For revisions: Adjusted to increased zoom on LSM980!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieve file names\n",
    "\n",
    "# Prep\n",
    "fnames = [fname for fname in os.listdir(dirpath) \n",
    "          if trigger in fname and fname.endswith(suffix)]\n",
    "fpaths = [os.path.join(dirpath, fname) for fname in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Run pipeline\n",
    "\n",
    "# For each file...\n",
    "for fname, fpath in zip(fnames, fpaths):\n",
    "    \n",
    "    # Report\n",
    "    print '\\nProcessing image \"' + fname + '\"'\n",
    "    \n",
    "    # Load raw\n",
    "    img = imread(fpath)\n",
    "    \n",
    "    # Organize dims and remove surplus channels\n",
    "    if 2 in img.shape:\n",
    "        img = np.rollaxis(img, img.shape.index(2))\n",
    "    elif 3 in img.shape:\n",
    "        img = np.rollaxis(img, img.shape.index(3))\n",
    "        img = img[:2, ...]\n",
    "    else:\n",
    "        raise IOError(\"Opened an image that does not have a valid channel dimension.\")\n",
    "        \n",
    "    # Get lumen position\n",
    "    lumen = 'none'\n",
    "    with open(os.path.join(os.path.split(fpath)[0], r\"metadata.txt\"), \"r\") as infile:\n",
    "        for line in infile.readlines():\n",
    "            line = line.strip()\n",
    "            line = line.split('\\t')\n",
    "            if line[0] in os.path.split(fpath)[1]:\n",
    "                lumen = np.array([int(value) for value in line[1:4]])\n",
    "                break\n",
    "    if lumen is 'none':\n",
    "        raise Exception(\"Appropriate lumen metadata not found. Aborting!\")\n",
    "        \n",
    "    # Crop to region around lumen\n",
    "    rs  = region_size\n",
    "    l   = lumen\n",
    "    ims = img.shape\n",
    "    if img.ndim == 4:\n",
    "        img = img[:, np.max([0, l[0]-rs[0]]) : np.min([l[0]+rs[0], ims[1]-1]), \n",
    "                     np.max([0, l[1]-rs[1]]) : np.min([l[1]+rs[1], ims[2]-1]), \n",
    "                     np.max([0, l[2]-rs[2]]) : np.min([l[2]+rs[2], ims[3]-1])]\n",
    "    elif img.ndim == 3:\n",
    "        img = img[:, np.max([0, l[1]-rs[1]]) : np.min([l[1]+rs[1], ims[1]-1]), \n",
    "                     np.max([0, l[2]-rs[2]]) : np.min([l[2]+rs[2], ims[2]-1])]\n",
    "        \n",
    "    # Report\n",
    "    print '  Loaded image of shape: ', str(img.shape)\n",
    "        \n",
    "    # Warn about saturation\n",
    "    if img[0,...].max() == 255:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('always')\n",
    "            warnings.warn(\"There is some saturation in this image!\")\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    # Perform background subtraction\n",
    "    mask_img_bgsub_global    = coloc.bgsub_global(img[1,...])\n",
    "    measure_img_bgsub_global = coloc.bgsub_global(img[0,...])\n",
    "    mask_img_bgsub_local     = coloc.bgsub_local(img[1,...], sigma=10)\n",
    "    \n",
    "    # Threshold and extract measurements, construct results dict\n",
    "    results = dict()\n",
    "    results['total_mean'] = np.mean(measure_img_bgsub_global)\n",
    "    results['total_sum']  = np.sum(measure_img_bgsub_global)\n",
    "    \n",
    "    global_otsu = coloc.thresh_detect(mask_img_bgsub_global, measure_img_bgsub_global)\n",
    "    results['global_otsu_thresh']     = global_otsu[0]\n",
    "    results['global_otsu_mean']       = global_otsu[1]\n",
    "    results['global_otsu_sum']        = global_otsu[2]\n",
    "    results['global_otsu_mean_ratio'] = global_otsu[3]\n",
    "    results['global_otsu_sum_ratio']  = global_otsu[4]\n",
    "    \n",
    "    global_series = coloc.thresh_series(mask_img_bgsub_global, measure_img_bgsub_global)\n",
    "    results['global_series_threshs']     = global_series[0]\n",
    "    results['global_series_means']       = global_series[1]\n",
    "    results['global_series_sums']        = global_series[2]\n",
    "    results['global_series_means_slope'] = global_series[3]\n",
    "    results['global_series_sums_slope']  = global_series[4]\n",
    "    \n",
    "    local_otsu = coloc.thresh_detect(mask_img_bgsub_local, measure_img_bgsub_global)\n",
    "    results['local_otsu_thresh']     = local_otsu[0]\n",
    "    results['local_otsu_mean']       = local_otsu[1]\n",
    "    results['local_otsu_sum']        = local_otsu[2]\n",
    "    results['local_otsu_mean_ratio'] = local_otsu[3]\n",
    "    results['local_otsu_sum_ratio']  = local_otsu[4]\n",
    "    \n",
    "    local_series = coloc.thresh_series(mask_img_bgsub_local, measure_img_bgsub_global)\n",
    "    results['local_series_threshs']    = local_series[0]\n",
    "    results['local_series_means']      = local_series[1]\n",
    "    results['local_series_slope']      = local_series[2]\n",
    "    results['local_series_means_slope'] = local_series[3]\n",
    "    results['local_series_sums_slope']  = local_series[4]    \n",
    "    \n",
    "    # Save measurements\n",
    "    with open(fpath[:-4]+\"_maskcoloc.pkl\", 'wb') as resultfile:\n",
    "        pickle.dump(results, resultfile, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    # Report\n",
    "    print '  Processing complete!'\n",
    "    \n",
    "# Final report\n",
    "print '\\nALL INPUT DATA PROCESSED!'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
