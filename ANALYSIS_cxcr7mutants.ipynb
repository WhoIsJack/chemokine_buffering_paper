{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Different Cxcr7 Mutants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- **Experiment & Data**\n",
    "    - Scope: 880 Airy-SR\n",
    "    - Structure: neuromasts\n",
    "    - Genetic background: wild-type\n",
    "    - Markers: \n",
    "        - BAC(Cxcr7) expressing different Cxcr7 mutants tagged with a green FP\n",
    "        - Red membrane marker (Lyn:Ruby) as counterlabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "# Generic\n",
    "from __future__ import division\n",
    "import os, sys\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Specific\n",
    "import re, pickle\n",
    "from ipywidgets import interact\n",
    "from util.widget_helpers import savebutton\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Settings\n",
    "\n",
    "# Path of dir containing data\n",
    "fpath = 'data_full'\n",
    "\n",
    "# Ordered list of experiments to load\n",
    "labels     = ['WT_20170507',\n",
    "              'WT_20170508',\n",
    "              'WT_20170509',\n",
    "              'WT_20170902',\n",
    "              'WT_20170903',\n",
    "              'WT_20180605',\n",
    "              'WT_20180606',\n",
    "              \n",
    "              'KA_20170508',\n",
    "              'KA_20170507',\n",
    "              \n",
    "              'STA_20180303',\n",
    "              'STA_20170501',\n",
    "              \n",
    "              'hs_20170722',\n",
    "              'hs_20170723',\n",
    "              'hs_20170724',\n",
    "              'hs_20170902',\n",
    "              'hs_20170903',\n",
    "              'hs_20180605',\n",
    "              'hs_20180606']\n",
    "\n",
    "# Dates to exclude\n",
    "exclude_dates = []\n",
    "\n",
    "# Dict of colors to represent the different experiments  \n",
    "color_dict = {'WT_20170507'     : 'springgreen',\n",
    "              'WT_20170508'     : 'springgreen',\n",
    "              'WT_20170509'     : 'springgreen',\n",
    "              'WT_20170902'     : 'springgreen',\n",
    "              'WT_20170903'     : 'springgreen',\n",
    "              'WT_20180605'     : 'springgreen',\n",
    "              'WT_20180606'     : 'springgreen',\n",
    "              'WT_20180605'     : 'springgreen',\n",
    "              'WT_20180606'     : 'springgreen',\n",
    "              'hsCTRL_20170722' : 'springgreen',\n",
    "              \n",
    "              'KA_20170508'     : 'lightskyblue', \n",
    "              'KA_20170507'     : 'lightskyblue',\n",
    "              'KAwt_20180302'   : 'lightskyblue',\n",
    "              \n",
    "              'STA_20180303'    : 'mediumorchid',\n",
    "              'STA_20170501'    : 'mediumorchid',\n",
    "              'STAwt_20180317'  : 'mediumorchid',\n",
    "              'STAwt_20180318'  : 'mediumorchid',\n",
    "              \n",
    "              'hs_20170722'     : 'red',\n",
    "              'hs_20170723'     : 'red',\n",
    "              'hs_20170724'     : 'red',\n",
    "              'hs_20170902'     : 'red',\n",
    "              'hs_20170903'     : 'red',\n",
    "              'hs_20180605'     : 'red',\n",
    "              'hs_20180606'     : 'red'}\n",
    "\n",
    "# Ordered list of experiment sets for grouping\n",
    "experiments = ['WT', 'KA', 'STA', 'HS']\n",
    "\n",
    "# Dict merging experiments into sets\n",
    "experiment_dict = {'WT_20170507'     : 'WT',\n",
    "                   'WT_20170508'     : 'WT',\n",
    "                   'WT_20170509'     : 'WT',\n",
    "                   'WT_20170902'     : 'WT',\n",
    "                   'WT_20170903'     : 'WT',\n",
    "                   'WT_20180605'     : 'WT',\n",
    "                   'WT_20180606'     : 'WT',\n",
    "                   'WT_20180605'     : 'WT',\n",
    "                   'WT_20180606'     : 'WT',\n",
    "                   'hsCTRL_20170722' : 'WT',\n",
    "                   \n",
    "                   'KA_20170508'     : 'KA', \n",
    "                   'KA_20170507'     : 'KA',\n",
    "                   'KAwt_20180302'   : 'KA',\n",
    "                   \n",
    "                   'STA_20180303'    : 'STA',\n",
    "                   'STA_20170501'    : 'STA',\n",
    "                   'STAwt_20180317'  : 'STA',\n",
    "                   'STAwt_20180318'  : 'STA',\n",
    "                   \n",
    "                   'hs_20170722'     : 'HS',\n",
    "                   'hs_20170723'     : 'HS',\n",
    "                   'hs_20170724'     : 'HS',\n",
    "                   'hs_20170902'     : 'HS',\n",
    "                   'hs_20170903'     : 'HS',\n",
    "                   'hs_20180605'     : 'HS',\n",
    "                   'hs_20180606'     : 'HS'}\n",
    "\n",
    "# Dict of colors for experiment sets\n",
    "experiment_color_dict = {'WT'   : 'springgreen',\n",
    "                         'KA'   : 'lightskyblue',\n",
    "                         'STA'  : 'mediumorchid',\n",
    "                         'HS'   : 'red'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Loading\n",
    "\n",
    "# Elaborate data loading & parsing function\n",
    "def load_data(fpath):\n",
    "\n",
    "    # Get filenames\n",
    "    fnames = [fname for fname in os.listdir(fpath) if fname.endswith('masked_LMs.npz')]\n",
    "\n",
    "    # Extract experiment labels and dates\n",
    "    label_pattern = re.compile(r'\\(([A-Za-z0-9_]+)\\)')\n",
    "    data_labels   = [re.search(label_pattern, fname).group(1) for fname in fnames]\n",
    "    date_pattern  = re.compile(r'_([0-9]{8})\\)')\n",
    "    data_dates    = [re.search(date_pattern, fname).group(1) for fname in fnames]\n",
    "    \n",
    "    # Keep only desired experiments\n",
    "    fnames      = [fname for fname,label,date in zip(fnames,data_labels,data_dates) \n",
    "                   if label in labels and not date in exclude_dates]\n",
    "    data_labels = [label for label,date in zip(data_labels,data_dates)\n",
    "                   if label in labels and not date in exclude_dates]\n",
    "    data_dates  = [date for label,date  in zip(data_labels,data_dates)\n",
    "                   if label in labels and not date in exclude_dates]\n",
    "    \n",
    "    # Sort according to experiment list\n",
    "    sort_indices = [labels.index(label) for label in data_labels]  # Get indices\n",
    "    data_labels  = [label for index,label in sorted(zip(sort_indices, data_labels))]  # Sort the labels\n",
    "    data_dates   = [date  for index,date  in sorted(zip(sort_indices, data_dates))]   # Sort the dates\n",
    "    fnames       = [fname for index,fname in sorted(zip(sort_indices, fnames))]       # Sort the filenames  \n",
    "    \n",
    "    # Metadata prep: load data\n",
    "    metadata = []\n",
    "    with open(os.path.join(fpath, r\"metadata.txt\"), \"r\") as infile:\n",
    "        for line in infile.readlines():\n",
    "            metadata.append(line.strip().split('\\t'))\n",
    "\n",
    "    # Metadata prep: int conversion function\n",
    "    def cint(astr):\n",
    "        try: return int(astr)\n",
    "        except ValueError: return np.nan            \n",
    "            \n",
    "    # Load the data\n",
    "    data_masked = []\n",
    "    data_memsub = []\n",
    "    data_intens = []\n",
    "    data_meta   = []\n",
    "    for fname in fnames:\n",
    "\n",
    "        # Load masked dataset\n",
    "        masked_LMs = np.load(os.path.join(fpath, fname))\n",
    "        data_masked.append(masked_LMs)\n",
    "\n",
    "        # Load memsubbed dataset\n",
    "        memsub_LMs = np.load(os.path.join(fpath, fname[:-8]+\"_memsub_LMs.npz\"))\n",
    "        data_memsub.append(memsub_LMs)\n",
    "        \n",
    "        # Load intensity values\n",
    "        with open(os.path.join(fpath, fname[:-14]+\"measurements.pkl\"),\"rb\") as infile:\n",
    "            data_intensity = pickle.load(infile)\n",
    "        data_intens.append(data_intensity)\n",
    "        \n",
    "        # Metadata: load corresponding values\n",
    "        for line in metadata:\n",
    "            if line[0]==fname[:-20]:\n",
    "                data_meta.append([cint(line[5]),cint(line[6])])\n",
    "                    \n",
    "    # Get the number of landmarks\n",
    "    num_lms = data_masked[0]['lm_cx7'].shape[0]\n",
    "        \n",
    "    # Unfold the .npz structure\n",
    "    data = {}\n",
    "    for key in data_masked[0].files:\n",
    "        data[key] = np.array([d[key] for d in data_masked])\n",
    "    for key in data_memsub[0].files:\n",
    "        data[key] = np.array([d[key] for d in data_memsub])\n",
    "        \n",
    "    # Unfold the intensity dicts\n",
    "    for key in data_intens[0].keys():\n",
    "        data['intensity_'+key] = np.array([d[key] for d in data_intens])\n",
    "        \n",
    "    # Unfold the metadata\n",
    "    for i,key in enumerate(['meta_time','meta_nm']):\n",
    "        data[key] = np.array([d[i] for d in data_meta])\n",
    "    \n",
    "    # Return results\n",
    "    return np.array(data_labels), num_lms, data\n",
    "\n",
    "# Call data loading func\n",
    "data_labels, num_lms, data = load_data(fpath)\n",
    "\n",
    "# Get sorted data keys\n",
    "data_keys = sorted(data.keys())\n",
    "\n",
    "# Remove labels of excluded dates\n",
    "labels = [label for label in labels if not label[-8:] in exclude_dates]\n",
    "\n",
    "# Get experiment labels\n",
    "data_experiments = np.array([experiment_dict[label] for label in data_labels])\n",
    "\n",
    "# Report\n",
    "print \"\\nLoaded\", len(data_labels), \"datasets with\", num_lms, \"landmarks per set.\"\n",
    "print \"\\nSamples per condition:\"\n",
    "for label in labels: print \"  {0:16}{1:>4}\".format(label, np.sum(data_labels==label))\n",
    "print \"\\nSamples per experiment:\"\n",
    "for experiment in experiments: print \"  {0:2}{1:>4}\".format(experiment, np.sum(data_experiments==experiment))\n",
    "print \"\\nAvailable measurements are:\"\n",
    "for key in data_keys: print \"  {0:<21}{1}\".format(key, data[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point Cloud Distribution Analysis: Apical Distance Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apical_distance_hist(d, label, bins=25, alpha=0.5,\n",
    "                         xlabel='', ylabel=''):\n",
    "\n",
    "    # Subsample to get everything to the same number of LMs\n",
    "    min_sample_nr  = num_lms * np.min(np.unique(data_experiments, return_counts=True)[1])\n",
    "    d = d[np.random.choice(np.arange(d.shape[0]),\n",
    "                           size=min_sample_nr, replace=False)]    \n",
    "    \n",
    "    # Get color\n",
    "    c = experiment_color_dict[label]\n",
    "    \n",
    "    # Make hist\n",
    "    plt.hist(d, bins=np.linspace(0, np.max(d), bins), \n",
    "             histtype='stepfilled', color=c, edgecolor=None, alpha=alpha, \n",
    "             label=label)\n",
    "    plt.hist(d, bins=np.linspace(0, np.max(d), bins), \n",
    "             histtype='step', color=c, alpha=1)\n",
    "    \n",
    "    # Labeling\n",
    "    plt.legend()\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Interactive Apical Distance Histogram\n",
    "\n",
    "# Initiate\n",
    "@interact(val=['memsub_lum_dist_cx7']+[v for v in data_keys if 'lum_dist' in v\n",
    "                                       and not v=='memsub_lum_dist_cx7'],\n",
    "          WT=True, KA=True, STA=True, HS=False)\n",
    "#@savebutton\n",
    "def interactive_hist(val='memsub_lum_dist_cx7',\n",
    "                     WT=True, KA=True, STA=True, HS=False):\n",
    "    \n",
    "    # Prep plot\n",
    "    plt.figure(figsize=(12,4))\n",
    "    \n",
    "    # Make the plots\n",
    "    for check, experiment in zip([WT,KA,STA,HS], experiments):\n",
    "        if check:\n",
    "            data_to_plot = data[val][data_experiments==experiment].flatten()\n",
    "            apical_distance_hist(data_to_plot, experiment)\n",
    "    \n",
    "    # Global plot cosmetics\n",
    "    plt.title(\"Apical Distance Histogram [\"+val+\"]\")\n",
    "    plt.xlabel(\"Distance from Lumen $[\\mu m]$\")\n",
    "    plt.ylabel(\"Number of Landmarks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point Cloud Distribution Analysis: Registered Overlays (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def registered_overlay_scatter(d, label, fig, ax, ylbl='y', clbl='z',\n",
    "                               xlim=[-50,50], ylim=[-20,20], vlim=[-0.5,1.5]):\n",
    "\n",
    "    # Subsample to get everything to the same number of LMs\n",
    "    min_sample_nr  = num_lms * np.min(np.unique(data_experiments, return_counts=True)[1])\n",
    "    d = d[np.random.choice(np.arange(d.shape[0]),\n",
    "                           size=min_sample_nr, replace=False)]    \n",
    "\n",
    "    # Make scatter plot\n",
    "    scat = ax.scatter(d[:,2], d[:,1], label=label,\n",
    "                      c=d[:,0], cmap='inferno', vmin=vlim[0], vmax=vlim[1],\n",
    "                      s=5, edgecolor='', alpha=0.5)\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar = fig.colorbar(scat, ax=ax)\n",
    "    cbar.set_label(clbl, rotation=270)\n",
    "\n",
    "    # Set limits\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "    # Label\n",
    "    ax.legend()\n",
    "    ax.set_ylabel(ylbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Interactive Landmark Overlays: XY\n",
    "\n",
    "# Initiate\n",
    "@interact(val=['lm_memsub_cx7_tf']+[v for v in data_keys if not 'lum_dist' in v \n",
    "                                    and 'tf' in v and not v=='lm_memsub_cx7_tf'])\n",
    "#@savebutton\n",
    "def interactive_hist(val=\"lm_memsub_cx7_tf\"):\n",
    "    \n",
    "    # Prep plot\n",
    "    fig, ax = plt.subplots(len(experiments), figsize=(10,3*len(experiments)),\n",
    "                           sharex=True, sharey=True)\n",
    "    \n",
    "    # Make the plots\n",
    "    for experiment,axis in zip(experiments, ax):\n",
    "        data_to_plot = data[val][data_experiments==experiment]\n",
    "        data_to_plot = np.concatenate(data_to_plot)\n",
    "        registered_overlay_scatter(data_to_plot, experiment, fig, axis, ylbl='y', clbl='z',\n",
    "                                   xlim=[-50,50], ylim=[-20,20], vlim=[-0.5,1.5])\n",
    "        \n",
    "    # Global plot cosmetics\n",
    "    plt.xlabel('x')\n",
    "    plt.suptitle('Registered Landmark Distributions (x,y) of '+val, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Interactive Landmark Overlays: XZ\n",
    "\n",
    "# Initiate\n",
    "@interact(val=[\"lm_memsub_cx7_tf\"]+[v for v in data_keys if not 'lum_dist' in v \n",
    "                                    and 'tf' in v and not v==\"lm_memsub_cx7_tf\"])\n",
    "@savebutton\n",
    "def interactive_hist(val=\"lm_memsub_cx7_tf\"):\n",
    "    \n",
    "    # Prep plot\n",
    "    fig, ax = plt.subplots(len(experiments), figsize=(10,3*len(experiments)),\n",
    "                           sharex=True, sharey=True)\n",
    "    \n",
    "    # Make the plots\n",
    "    for experiment,axis in zip(experiments, ax):\n",
    "        data_to_plot = data[val][data_experiments==experiment]\n",
    "        data_to_plot = np.concatenate(data_to_plot)\n",
    "        data_to_plot = data_to_plot[:,[1,0,2]]       # Changing the axis\n",
    "        registered_overlay_scatter(data_to_plot, experiment, fig, axis, ylbl='z', clbl='y',\n",
    "                                   xlim=[-50,50], ylim=[-0.5,1.5], vlim=[-20,20])\n",
    "        \n",
    "    # Global plot cosmetics\n",
    "    plt.xlabel('x')\n",
    "    plt.suptitle('Registered Landmark Distributions (x,z) of '+val, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intensity Analysis: Absolute Intensity Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_absolute_boxplot(d, val, pool=False):\n",
    "\n",
    "    # Pool by experiments\n",
    "    # Note: This is a bit hamfisted but it works for now.\n",
    "    if pool:\n",
    "        exp_d = []\n",
    "        for exp in experiments:\n",
    "            exp_d.append([])\n",
    "            for dset, lbl in zip(d, labels):\n",
    "                if experiment_dict[lbl] == exp:\n",
    "                    exp_d[-1].append(dset)\n",
    "            exp_d[-1] = np.concatenate(exp_d[-1])\n",
    "        d = exp_d\n",
    "        lbls  = experiments\n",
    "        cdict = experiment_color_dict\n",
    "    else:\n",
    "        lbls  = labels\n",
    "        cdict = color_dict\n",
    "        \n",
    "    # Prep\n",
    "    fig, ax = plt.subplots(1, figsize=(len(lbls),4))\n",
    "    \n",
    "    # Create boxplot\n",
    "    bp = ax.boxplot(d, showfliers=False, widths=0.7)\n",
    "\n",
    "    # Boxplot cosmetics\n",
    "    for item in ['boxes', 'whiskers']:\n",
    "        plt.setp(bp[item], color='k', linestyle='-')\n",
    "    ax.set_xticklabels([lbl+\" (N=\"+str(len(d[idx]))+\")\" \n",
    "                        for idx,lbl in enumerate(lbls)])\n",
    "    plt.setp(bp['medians'], color='r', alpha=0.5, linewidth=1.2)\n",
    "    fig.autofmt_xdate()\n",
    "    ax.set_title(\"Mean Intensity: \"+val[10:])\n",
    "        \n",
    "    # Add jittered data\n",
    "    for i,label in enumerate(lbls):\n",
    "        y = d[i]                                      # Values\n",
    "        x = np.random.normal(i+1, 0.08, size=len(y))  # Jitter\n",
    "        ax.scatter(x, y, c=cdict[label], \n",
    "                   alpha=0.7, edgecolor='', s=20)\n",
    "\n",
    "    # Axis cosmetics\n",
    "    ax.set_ylim([ax.get_ylim()[0] - ax.get_ylim()[0] * 0.1, \n",
    "                 ax.get_ylim()[1] + ax.get_ylim()[1] * 0.1])\n",
    "    ax.set_ylabel(\"Mean Intensity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Interactive Absolute Intensity Boxplot\n",
    "\n",
    "# Initiate\n",
    "time_max = int(np.nanmax(data[\"meta_time\"]))\n",
    "@interact(val=['intensity_all_cx7']+[v for v in data_keys if 'intensity' in v\n",
    "                                     and not v=='intensity_all_cx7'],\n",
    "          time_thresh=(0,time_max), pool=False)\n",
    "#@savebutton\n",
    "def interactive_rbp(val='intensity_all_cx7', \n",
    "                    time_thresh=0, pool=False):\n",
    "    \n",
    "    # Get data\n",
    "    d = [data[val][data_labels==label] for label in labels]\n",
    "    \n",
    "    # For pooling, data should be control-normed (but it can't be here)\n",
    "    if pool:\n",
    "        import warnings\n",
    "        warnings.warn(\"Pooling makes no sense without normalization \"+\n",
    "                      \"and normalization is not possible here!\")\n",
    "        \n",
    "    # Keep only those older than time_thresh (where time data is available)\n",
    "    if not time_thresh == 0:\n",
    "        t = [data[\"meta_time\"][data_labels==label] for label in labels]\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            for i,dd,tt in zip(range(len(d)),d,t):\n",
    "                d[i] = dd[np.logical_or(tt > time_thresh, np.isnan(tt))]\n",
    "                         \n",
    "    # Make the plot\n",
    "    intensity_absolute_boxplot(d, val, pool=pool)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "00f069936ec84710b3447210cc99178a": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "4cfc2d31da6742a092ed7d23a4d9b415": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "691e0a93ef3e45c88bb42567422ff44a": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "bf5f0d04b2614aad82abf1371f8d0127": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "d2b161f6e7ba475ab0905d2d53e8424e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
